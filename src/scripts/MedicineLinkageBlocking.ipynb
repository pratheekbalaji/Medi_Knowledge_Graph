{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(s, n=3):\n",
    "    return [s[i:i + n] for i in range(len(s) - (n - 1))]\n",
    "\n",
    "\n",
    "# bg = rltk.TokenBlockGenerator()\n",
    "\n",
    "# block = bg.generate(\n",
    "# bg.block(ds_wiki, function_ = lambda r:n_gram(r.name_string,3)),\n",
    "# bg.block(ds_webmd, function_=lambda r: n_gram(r.genname_string, 3))\n",
    "\n",
    "# )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import *\n",
    "from re import sub as re_sub\n",
    "import sys\n",
    "import json\n",
    "import rltk\n",
    "from collections import defaultdict\n",
    "\n",
    "global g_tokenizer\n",
    "g_tokenizer = rltk.CrfTokenizer()\n",
    "\n",
    "class WikiRecord(rltk.Record):\n",
    "    ''' Record entry class for each of our IMDB records '''\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['MedicineURI']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def name_string(self):\n",
    "        return self.raw_object['Medicine'].lower()\n",
    "\n",
    "class WebMDRecord(rltk.Record):\n",
    "    ''' Record entry class for each of our AFI records '''\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['url']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def genname_string(self):\n",
    "        return self.raw_object['Generic_Name']\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def brandname_string(self):\n",
    "        return self.raw_object['Brand_Name'].lower()\n",
    "\n",
    "def n_gram(s, n=3):\n",
    "    return [s[i:i + n] for i in range(len(s) - (n - 1))]\n",
    "\n",
    "\n",
    "def create_dataset(input_file: str, rcrd_class: rltk.Record) -> rltk.Dataset:\n",
    "    ''' Create rltk dataset from a given jl file '''\n",
    "    assert Path(input_file).suffix == \".jl\"\n",
    "    return rltk.Dataset(reader=rltk.JsonLinesReader(input_file), record_class=rcrd_class, adapter=rltk.MemoryKeyValueAdapter())\n",
    "\n",
    "\n",
    "#def get_ground_truth(input_file: str, ds1: rltk.Dataset, ds2: rltk.Dataset) -> rltk.GroundTruth:\n",
    "#    ''' Read the grouth truth from the given input file '''\n",
    "#    devset_file_handle = open(input_file, \"r\")\n",
    "#    devset_data = json.load(devset_file_handle)\n",
    "#    gt = rltk.GroundTruth()\n",
    "#    for item in devset_data:\n",
    "#        if None != item['afi_movie']:\n",
    "#            r_imdb = ds1.get_record(item['imdb_movie'])\n",
    "#            r_afi  = ds2.get_record(item['afi_movie'])\n",
    "#            gt.add_positive(r_imdb.raw_object['url'], r_afi.raw_object['url'])\n",
    "#    return gt\n",
    "\n",
    "def med_name_similarity(r_wiki,r_webmd):\n",
    "    name_wiki=r_wiki.name_string.lower()\n",
    "    name_wedgenmd=r_webmd.genname_string.lower()\n",
    "    name_wedbrandmd=r_webmd.brandname_string.lower()\n",
    "\n",
    "    name_wedgenmd=name_wedgenmd.replace(\" \", \"\")\n",
    "    name_wedbrandmd=name_wedbrandmd.replace(\" \", \"\")\n",
    "\n",
    "\n",
    "    if ' ' in name_wiki:\n",
    "        name_wiki=name_wiki.split(' ')\n",
    "        name_wiki=max(name_wiki, key=len)\n",
    "    elif '-' in name_wiki:\n",
    "        name_wiki=name_wiki.split('-')\n",
    "        name_wiki=max(name_wiki, key=len)\n",
    "    elif '/' in name_wiki:\n",
    "        name_wiki=name_wiki.split('/')\n",
    "        name_wiki=max(name_wiki, key=len)\n",
    "\n",
    "    if name_wiki in name_wedgenmd or name_wiki in name_wedbrandmd :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "wiki_file = \"/Users/sharadsharma/Documents/KG/Project/WikiMedTest.jl\"\n",
    "webmd_file = \"/Users/sharadsharma/Documents/KG/Project/WebMDTest.jl\"\n",
    "ds_wiki = create_dataset(wiki_file, WikiRecord)\n",
    "ds_webmd = create_dataset(webmd_file, WebMDRecord)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bg = rltk.TokenBlockGenerator()\n",
    "\n",
    "block = bg.generate(\n",
    "bg.block(ds_wiki, function_ = lambda r:n_gram(r.name_string,3)),\n",
    "bg.block(ds_webmd, function_=lambda r: n_gram(r.genname_string, 3))\n",
    "\n",
    ")\n",
    "block2  = bg.generate(\n",
    "bg.block(ds_wiki, function_ = lambda r:n_gram(r.name_string,3)),\n",
    "bg.block(ds_webmd, function_=lambda r: n_gram(r.brandname_string, 3))\n",
    "\n",
    ")\n",
    "\n",
    "    \n",
    "pred_dic = defaultdict(set)\n",
    "pairs =list(set(block.pairwise(ds_wiki,ds_webmd)))\n",
    "pairs_2 = list(set(block2.pairwise(ds_wiki,ds_webmd)))\n",
    "pairs.extend(pairs_2)\n",
    "\n",
    "\n",
    "for a,b,c in pairs:\n",
    "      \n",
    "    flag = False\n",
    "    r_wiki = ds_wiki.get_record(b)\n",
    "    r_webmd = ds_webmd.get_record(c)\n",
    "\n",
    "    value=med_name_similarity(r_wiki, r_webmd)\n",
    "    if value==True:\n",
    "        flag=True\n",
    "       \n",
    "        \n",
    "        \n",
    "        pred_dic[b].add(c)\n",
    "\n",
    "\n",
    "    if flag==False:\n",
    "        pred_dic[b].add(None)\n",
    "\n",
    "for k,v in pred_dic.items():\n",
    "    if len(pred_dic[k]) >1:\n",
    "        pred_dic[k].remove(None)\n",
    "res = []\n",
    "for k,v in pred_dic.items():\n",
    "    temp = {}\n",
    "    temp['wiki_url'] =k\n",
    "    temp['webmd_url'] = list(v)[0]\n",
    "    res.append(temp)\n",
    "    \n",
    "   \n",
    "\n",
    "with open('/Users/sharadsharma/Documents/KG/Project/MedicineLinkageTest.jl','w') as op_file:\n",
    "     json.dump(res,op_file,indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
